{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitvenvvirtualenvb1b95c205e884dfa96c39310c8bb52e1",
   "display_name": "Python 3.7.6 64-bit ('venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "from os import path, sys\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "BRIGHT_QUBITS_DATASETS = [\n",
    "    'Data4Jens/BrightTimeTagSet1.csv',\n",
    "    'Data4Jens/BrightTimeTagSet2.csv',\n",
    "    'Data4Jens/BrightTimeTagSet3.csv',\n",
    "    'Data4Jens/BrightTimeTagSet4.csv',\n",
    "    'Data4Jens/BrightTimeTagSet5.csv',\n",
    "]\n",
    "\n",
    "DARK_QUBITS_DATASETS = [\n",
    "    'Data4Jens/DarkTimeTagSet1.csv',\n",
    "    'Data4Jens/DarkTimeTagSet2.csv',\n",
    "    'Data4Jens/DarkTimeTagSet3.csv',\n",
    "    'Data4Jens/DarkTimeTagSet4.csv',\n",
    "    'Data4Jens/DarkTimeTagSet5.csv',\n",
    "]\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "BEST_ARRIVAL_TIME_THRESHOLD = 0.00529914\n",
    "\n",
    "PRE_ARRIVAL_TIME_THRESHOLD = 0.000722906  # from \"Distribution of Photons Arrival Times\" graph\n",
    "POST_ARRIVAL_TIME_THRESHOLD = 0.00522625\n",
    "\n",
    "\n",
    "def log(message):\n",
    "    # sys.stderr.write(message + '\\n')\n",
    "    print(message, file=sys.stderr)\n",
    "\n",
    "\n",
    "class Histogramize(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, arrival_time_threshold=(0, BEST_ARRIVAL_TIME_THRESHOLD), num_buckets=6):\n",
    "        self.arrival_time_threshold = arrival_time_threshold\n",
    "        self.num_buckets = num_buckets\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        histogram_bins = np.linspace(\n",
    "            self.arrival_time_threshold[0], self.arrival_time_threshold[1], \n",
    "            num=(self.num_buckets+1), endpoint=True)\n",
    "        return list(map(\n",
    "            lambda measurement: np.histogram(measurement, bins=histogram_bins)[0], X))\n",
    "\n",
    "\n",
    "# MLP Classifier\n",
    "def load_datasets():\n",
    "    def load_datasets_with_ground_truth(qubits_datasets, ground_truth):\n",
    "        qubits_measurements = []\n",
    "        for dataset_filename in qubits_datasets:\n",
    "            with open(dataset_filename, 'r') as dataset_file:\n",
    "                log(\"Loading {}\".format(dataset_filename))\n",
    "                csv_reader = csv.reader(dataset_file)\n",
    "                for line in csv_reader:\n",
    "                    qubits_measurements.append(\n",
    "                        np.array(list(map(lambda timestamp: float(timestamp), line)))\n",
    "                    )\n",
    "        qubits_ground_truths = [ground_truth for i in range(len(qubits_measurements))]\n",
    "        return qubits_measurements, qubits_ground_truths\n",
    "    \n",
    "    bright_qubits_measurements, bright_qubits_ground_truths = load_datasets_with_ground_truth(BRIGHT_QUBITS_DATASETS, 0)\n",
    "    dark_qubits_measurements, dark_qubits_ground_truths = load_datasets_with_ground_truth(DARK_QUBITS_DATASETS, 1)\n",
    "    return (\n",
    "        (bright_qubits_measurements + dark_qubits_measurements), \n",
    "        (bright_qubits_ground_truths + dark_qubits_ground_truths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Starting MLPClassifier Grid Search with Cross Validation Method.\nLoading Data4Jens/BrightTimeTagSet1.csv\nLoading Data4Jens/BrightTimeTagSet2.csv\nLoading Data4Jens/BrightTimeTagSet3.csv\nLoading Data4Jens/BrightTimeTagSet4.csv\nLoading Data4Jens/BrightTimeTagSet5.csv\nLoading Data4Jens/DarkTimeTagSet1.csv\nLoading Data4Jens/DarkTimeTagSet2.csv\nLoading Data4Jens/DarkTimeTagSet3.csv\nLoading Data4Jens/DarkTimeTagSet4.csv\nLoading Data4Jens/DarkTimeTagSet5.csv\nFitting 5 folds for each of 1 candidates, totalling 5 fits\nStarting Grid Search with Cross Validation on MLP Classifier.\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   57.5s remaining:  1.4min\n[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=<generator object _BaseKFold.split at 0x128fc07d0>,\n             error_score=nan,\n             estimator=Pipeline(memory=None,\n                                steps=[('hstgm',\n                                        Histogramize(arrival_time_threshold=(0,\n                                                                             0.00522625),\n                                                     num_buckets=6)),\n                                       ('clf',\n                                        MLPClassifier(activation='relu',\n                                                      alpha=0.0001,\n                                                      batch_size='auto',\n                                                      beta_1=0.9, beta_2=0.999,\n                                                      early_stopping=False,\n                                                      epsilon=1e-08,\n                                                      hidden_layer_sizes=(100,),\n                                                      le...\n                                                      momentum=0.9,\n                                                      n_iter_no_change=10,\n                                                      nesterovs_momentum=True,\n                                                      power_t=0.5,\n                                                      random_state=None,\n                                                      shuffle=True,\n                                                      solver='adam', tol=0.0001,\n                                                      validation_fraction=0.1,\n                                                      verbose=False,\n                                                      warm_start=False))],\n                                verbose=False),\n             iid='deprecated', n_jobs=-1,\n             param_grid={'clf__hidden_layer_sizes': [(8, 8)]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='accuracy', verbose=2)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(\"Starting MLPClassifier Grid Search with Cross Validation Method.\")\n",
    "\n",
    "qubits_measurements, qubits_truths = load_datasets()\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "qubits_class = []\n",
    "assert(len(qubits_measurements) == len(qubits_truths))\n",
    "for index in range(len(qubits_measurements)):\n",
    "    qubits_class.append(qubits_truths[index] * 100 + len(qubits_measurements[index]))\n",
    "cv_indices = kf.split(qubits_measurements, qubits_class)\n",
    "\n",
    "log(\"Starting Grid Search with Cross Validation on MLP Classifier.\")\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "    # ('hstgm', Histogramize(num_buckets=6)),\n",
    "    # ('hstgm', Histogramize(arrival_time_threshold=(0, POST_ARRIVAL_TIME_THRESHOLD))),\n",
    "    ('hstgm', Histogramize(num_buckets=6, arrival_time_threshold=(0, POST_ARRIVAL_TIME_THRESHOLD))),\n",
    "    ('clf', MLPClassifier(activation='relu', solver='adam'))\n",
    "])\n",
    "\n",
    "mlp_param_grid = {\n",
    "    # 'hstgm__num_buckets': range(1, 33),\n",
    "    # 'hstgm__arrival_time_threshold': [(0, BEST_ARRIVAL_TIME_THRESHOLD), (0, POST_ARRIVAL_TIME_THRESHOLD)],\n",
    "    'clf__hidden_layer_sizes': [(n,) * 2 for n in range(8, 9)]\n",
    "    # 'clf__learning_rate_init': [0.001, 0.0005],\n",
    "    # 'clf__max_iter': [200, 500]\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(mlp_pipeline, cv=cv_indices, n_jobs=-1, param_grid=mlp_param_grid, scoring=\"accuracy\", refit=True, verbose=2)\n",
    "mlp_grid.fit(qubits_measurements, qubits_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2\n"
    }
   ],
   "source": [
    "# pickle.dump(mlp_grid, open('/tmp/pickle_test_mlp.pkl', 'wb'))\n",
    "cv_indices = kf.split(qubits_measurements, qubits_class)\n",
    "print(len(list(cv_indices)[0]))\n",
    "# for train, test in cv_indices:\n",
    "#     print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.999705527544356]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log(mlp_grid.cv_results_)\n",
    "# print(\"Best parameters found in Grid Search:\")\n",
    "# print(mlp_grid.best_params_)\n",
    "list(mlp_grid.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Loading Data4Jens/BrightTimeTagSet1.csv\nLoading Data4Jens/BrightTimeTagSet2.csv\nLoading Data4Jens/BrightTimeTagSet3.csv\nLoading Data4Jens/BrightTimeTagSet4.csv\nLoading Data4Jens/BrightTimeTagSet5.csv\nLoading Data4Jens/DarkTimeTagSet1.csv\nLoading Data4Jens/DarkTimeTagSet2.csv\nLoading Data4Jens/DarkTimeTagSet3.csv\nLoading Data4Jens/DarkTimeTagSet4.csv\nLoading Data4Jens/DarkTimeTagSet5.csv\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.1min remaining:  1.6min\nScores of Cross Validation Method on MLPClassifier: \n{'fit_time': array([33.30896091, 29.87536621, 34.75128102, 28.94240999, 26.36837196]), 'score_time': array([3.5192461 , 3.59007597, 3.13400793, 2.70515418, 2.4573729 ]), 'test_score': array([0.99974169, 0.99971586, 0.99971586, 0.99969003, 0.99970294])}\n[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
    }
   ],
   "source": [
    "# run_mlp_with_cross_validation_average\n",
    "qubits_measurements, qubits_truths = load_datasets()\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "        ('hstgm', Histogramize(num_buckets=6, arrival_time_threshold=(0, POST_ARRIVAL_TIME_THRESHOLD))),\n",
    "        ('clf', MLPClassifier(hidden_layer_sizes=(32, 32), activation='relu', solver='adam'))\n",
    "    ])\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "qubits_class = []\n",
    "assert(len(qubits_measurements) == len(qubits_truths))\n",
    "for index in range(len(qubits_measurements)):\n",
    "    qubits_class.append(qubits_truths[index] * 100 + len(qubits_measurements[index]))\n",
    "cv_indices = kf.split(qubits_measurements, qubits_class)\n",
    "\n",
    "cv_scores = cross_validate(mlp_pipeline, qubits_measurements, qubits_truths, cv=cv_indices, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "print(\"Scores of Cross Validation Method on MLPClassifier: \")\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.99974169, 0.99971586, 0.99971586, 0.99969003, 0.99970294])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(list(cv_scores['test_score'])) / len(list(cv_scores['test_score']))\n",
    "cv_scores['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Loading Data4Jens/BrightTimeTagSet1.csv\nLoading Data4Jens/BrightTimeTagSet2.csv\nLoading Data4Jens/BrightTimeTagSet3.csv\nLoading Data4Jens/BrightTimeTagSet4.csv\nLoading Data4Jens/BrightTimeTagSet5.csv\nLoading Data4Jens/DarkTimeTagSet1.csv\nLoading Data4Jens/DarkTimeTagSet2.csv\nLoading Data4Jens/DarkTimeTagSet3.csv\nLoading Data4Jens/DarkTimeTagSet4.csv\nLoading Data4Jens/DarkTimeTagSet5.csv\n"
    }
   ],
   "source": [
    "qubits_measurements, qubits_truths = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "77"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(map(lambda measurement: len(measurement), qubits_measurements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}